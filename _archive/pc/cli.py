# -*- coding: utf-8 -*-
"""
pc/cli.py
PCìš© CLI ì¸í„°í˜ì´ìŠ¤ (ì‹¤ì „ ìš´ì˜)
"""
import argparse
import sys
from pathlib import Path
from datetime import date, datetime, timedelta
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from infra.data.updater import DataUpdater
from core.data.filtering import ETFFilter, get_filtered_universe
from extensions.backtest.runner import create_default_runner, create_momentum_runner
from extensions.backtest.report import create_report
from extensions.optuna.objective import create_objective

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def cmd_update_data(args):
    """ë°ì´í„° ì—…ë°ì´íŠ¸ ëª…ë ¹"""
    logger.info("=" * 60)
    logger.info("ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘")
    logger.info("=" * 60)
    
    # ë‚ ì§œ íŒŒì‹±
    if args.date == 'auto':
        end_date = date.today()
    else:
        end_date = datetime.strptime(args.date, '%Y-%m-%d').date()
    
    # ì‹œì‘ì¼ (ê¸°ë³¸: 1ë…„ ì „)
    start_date = end_date - timedelta(days=365)
    
    # ìœ ë‹ˆë²„ìŠ¤ í•„í„°ë§
    universe = get_filtered_universe()
    
    logger.info(f"ìœ ë‹ˆë²„ìŠ¤: {len(universe)}ê°œ ì¢…ëª©")
    logger.info(f"ê¸°ê°„: {start_date} ~ {end_date}")
    
    # ë°ì´í„° ì—…ë°ì´íŠ¸
    updater = DataUpdater()
    
    if args.symbols:
        # íŠ¹ì • ì¢…ëª©ë§Œ
        symbols = args.symbols.split(',')
        for symbol in symbols:
            updater.update_symbol(symbol.strip(), end_date, force=args.force)
    else:
        # ì „ì²´ ìœ ë‹ˆë²„ìŠ¤
        updater.update_universe(universe, end_date, force=args.force)
    
    logger.info("=" * 60)
    logger.info("ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    logger.info("=" * 60)
    
    return 0


def cmd_backtest(args):
    """ë°±í…ŒìŠ¤íŠ¸ ëª…ë ¹"""
    logger.info("=" * 60)
    logger.info("ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 60)
    
    # ë‚ ì§œ íŒŒì‹±
    start_date = datetime.strptime(args.start, '%Y-%m-%d').date()
    
    if args.end == 'today':
        end_date = date.today()
    else:
        end_date = datetime.strptime(args.end, '%Y-%m-%d').date()
    
    logger.info(f"ê¸°ê°„: {start_date} ~ {end_date}")
    logger.info(f"ì´ˆê¸° ìë³¸: {args.capital:,}ì›")
    logger.info(f"ìµœëŒ€ ë³´ìœ  ì¢…ëª©: {args.max_positions}ê°œ")
    logger.info(f"ë¦¬ë°¸ëŸ°ì‹±: {args.rebalance}")
    
    # ìœ ë‹ˆë²„ìŠ¤
    if args.universe:
        universe = args.universe.split(',')
    else:
        universe = get_filtered_universe()
    
    logger.info(f"ìœ ë‹ˆë²„ìŠ¤: {len(universe)}ê°œ ì¢…ëª©")
    
    # ê°€ê²© ë°ì´í„° ë¡œë“œ (lookback ê³ ë ¤í•˜ì—¬ ë” ë§ì€ ë°ì´í„° ë¡œë“œ)
    from infra.data.loader import load_price_data
    lookback_days = 120  # 60ì¼ lookback + ì—¬ìœ 
    data_start_date = start_date - timedelta(days=lookback_days)
    price_data = load_price_data(universe, data_start_date, end_date)
    
    if price_data.empty:
        logger.error("ê°€ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
        return 1
    
    # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (MAPS ì „ëµ)
    runner = create_default_runner(
        initial_capital=args.capital,
        max_positions=args.max_positions
    )
    
    result = runner.run(
        price_data=price_data,
        start_date=start_date,
        end_date=end_date,
        universe=universe,
        rebalance_frequency=args.rebalance
    )
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report = create_report(result)
    
    # ì½˜ì†” ì¶œë ¥
    print("\n" + report.generate_summary())
    
    # íŒŒì¼ ì €ì¥
    if args.output:
        output_dir = Path(args.output)
        report.save_to_file(output_dir)
        logger.info(f"ë¦¬í¬íŠ¸ ì €ì¥: {output_dir}")
    
    logger.info("=" * 60)
    logger.info("ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info("=" * 60)
    
    return 0


def cmd_scan(args):
    """ìŠ¤ìº” ëª…ë ¹ (ë§¤ë§¤ ì‹ í˜¸ ìƒì„±)"""
    logger.info("=" * 60)
    logger.info("ë§¤ë§¤ ì‹ í˜¸ ìŠ¤ìº” ì‹œì‘")
    logger.info("=" * 60)
    
    # ë‚ ì§œ íŒŒì‹±
    if args.date == 'auto':
        scan_date = date.today()
    else:
        scan_date = datetime.strptime(args.date, '%Y-%m-%d').date()
    
    logger.info(f"ìŠ¤ìº” ë‚ ì§œ: {scan_date}")
    
    # ìœ ë‹ˆë²„ìŠ¤
    universe = get_filtered_universe()
    
    logger.info(f"ìœ ë‹ˆë²„ìŠ¤: {len(universe)}ê°œ ì¢…ëª©")
    
    # ì‹ í˜¸ ìƒì„±
    from core.strategy.signals import create_default_signal_generator
    from infra.data.loader import load_price_data
    
    signal_generator = create_default_signal_generator()
    
    # ìµœê·¼ 60ì¼ ë°ì´í„°
    start_date = scan_date - timedelta(days=120)
    price_data = load_price_data(universe, start_date, scan_date)
    
    if price_data.empty:
        logger.error("ê°€ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 1
    
    # ì¢…ëª©ë³„ ì‹ í˜¸ ìƒì„±
    signals = []
    
    for symbol in universe:
        try:
            if symbol not in price_data.index.get_level_values('code'):
                continue
            
            symbol_data = price_data.loc[symbol]
            symbol_data = symbol_data[symbol_data.index <= scan_date]
            
            if len(symbol_data) < 60:
                continue
            
            recent_data = symbol_data.tail(60)
            
            result = signal_generator.generate_combined_signal(
                close=recent_data['close'],
                high=recent_data.get('high'),
                low=recent_data.get('low'),
                volume=recent_data.get('volume')
            )
            
            if result['signal'] == 'BUY' and result['confidence'] >= args.min_confidence:
                signals.append({
                    'symbol': symbol,
                    'signal': result['signal'],
                    'confidence': result['confidence'],
                    'price': recent_data['close'].iloc[-1],
                    'components': result.get('components', {})
                })
        
        except Exception as e:
            logger.debug(f"ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨ ({symbol}): {e}")
    
    # ì‹ ë¢°ë„ ìˆœ ì •ë ¬
    signals.sort(key=lambda x: x['confidence'], reverse=True)
    
    # ìƒìœ„ Nê°œ
    top_signals = signals[:args.top_n]
    
    # ì¶œë ¥
    print("\n" + "=" * 60)
    print(f"ë§¤ë§¤ ì‹ í˜¸ ({len(top_signals)}ê°œ)")
    print("=" * 60)
    
    for i, sig in enumerate(top_signals, 1):
        print(f"{i}. {sig['symbol']}: {sig['signal']} "
              f"(ì‹ ë¢°ë„: {sig['confidence']:.2%}, ê°€ê²©: {sig['price']:,.0f})")
    
    print("=" * 60)
    
    # íŒŒì¼ ì €ì¥
    if args.output:
        import pandas as pd
        df = pd.DataFrame(top_signals)
        output_file = Path(args.output)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        logger.info(f"ì‹ í˜¸ ì €ì¥: {output_file}")
    
    # í…”ë ˆê·¸ë¨ ì•Œë¦¼
    if args.notify:
        try:
            from infra.notify.telegram import send_to_telegram
            
            message = f"*[ì¥ë§ˆê°] ë§¤ë§¤ ì‹ í˜¸ ì•Œë¦¼*\n\n"
            message += f"ğŸ“… ë‚ ì§œ: {scan_date}\n"
            message += f"ğŸ“Š ì‹ í˜¸ ìˆ˜: {len(top_signals)}ê°œ\n\n"
            
            for i, sig in enumerate(top_signals, 1):
                message += f"{i}. `{sig['symbol']}`: *{sig['signal']}*\n"
                message += f"   ì‹ ë¢°ë„: {sig['confidence']:.1%} | ê°€ê²©: {sig['price']:,.0f}ì›\n"
            
            send_to_telegram(message)
            logger.info("í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì‹¤íŒ¨: {e}")
    
    logger.info("=" * 60)
    logger.info("ìŠ¤ìº” ì™„ë£Œ")
    logger.info("=" * 60)
    
    return 0


def cmd_optimize(args):
    """íŒŒë¼ë¯¸í„° ìµœì í™” ëª…ë ¹ (Optuna)"""
    logger.info("=" * 60)
    logger.info("íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘ (Optuna)")
    logger.info("=" * 60)
    
    import optuna
    import yaml
    from datetime import datetime
    
    # ë‚ ì§œ íŒŒì‹±
    start_date = datetime.strptime(args.start, '%Y-%m-%d').date()
    
    if args.end == 'today':
        end_date = date.today()
    else:
        end_date = datetime.strptime(args.end, '%Y-%m-%d').date()
    
    logger.info(f"ìµœì í™” ê¸°ê°„: {start_date} ~ {end_date}")
    logger.info(f"Trials: {args.trials}, Timeout: {args.timeout}ì´ˆ")
    logger.info(f"ëª©ì í•¨ìˆ˜: ì—°ìœ¨í™” ìˆ˜ìµë¥  - {args.mdd_lambda} Ã— MDD")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    if args.output:
        output_dir = Path(args.output)
    else:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = Path(f'reports/optuna/study_{timestamp}')
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Optuna study ìƒì„±
    study_name = f"krx_alertor_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    storage_path = output_dir / 'study.db'
    
    study = optuna.create_study(
        study_name=study_name,
        storage=f'sqlite:///{storage_path}',
        direction='maximize',
        load_if_exists=True,
        sampler=optuna.samplers.TPESampler(seed=args.seed) if args.seed else None
    )
    
    # ëª©ì  í•¨ìˆ˜ ìƒì„±
    objective = create_objective(
        start_date=start_date,
        end_date=end_date,
        initial_capital=args.capital,
        mdd_penalty_lambda=args.mdd_lambda,
        seed=args.seed
    )
    
    # ìµœì í™” ì‹¤í–‰
    logger.info("ìµœì í™” ì‹¤í–‰ ì¤‘...")
    
    try:
        study.optimize(
            objective,
            n_trials=args.trials,
            timeout=args.timeout,
            show_progress_bar=True
        )
    except KeyboardInterrupt:
        logger.warning("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    
    # ê²°ê³¼ ì €ì¥
    logger.info("=" * 60)
    logger.info("ìµœì í™” ì™„ë£Œ")
    logger.info("=" * 60)
    
    # ìµœì  íŒŒë¼ë¯¸í„°
    best_params = study.best_params
    best_value = study.best_value
    
    logger.info(f"ìµœì  ëª©ì í•¨ìˆ˜ ê°’: {best_value:.4f}")
    logger.info(f"ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
    
    # ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥
    params_file = output_dir / 'best_params.yaml'
    with open(params_file, 'w', encoding='utf-8') as f:
        yaml.dump(best_params, f, allow_unicode=True)
    
    logger.info(f"ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥: {params_file}")
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report_file = output_dir / 'study_report.md'
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"# Optuna ìµœì í™” ë¦¬í¬íŠ¸\n\n")
        f.write(f"## ì„¤ì •\n\n")
        f.write(f"- ê¸°ê°„: {start_date} ~ {end_date}\n")
        f.write(f"- Trials: {len(study.trials)}\n")
        f.write(f"- ëª©ì í•¨ìˆ˜: ì—°ìœ¨í™” ìˆ˜ìµë¥  - {args.mdd_lambda} Ã— MDD\n")
        f.write(f"- ì´ˆê¸° ìë³¸: {args.capital:,}ì›\n\n")
        
        f.write(f"## ìµœì  ê²°ê³¼\n\n")
        f.write(f"- ëª©ì í•¨ìˆ˜ ê°’: {best_value:.4f}\n")
        
        # ìµœì  trialì˜ ë©”íŠ¸ë¦­
        best_trial = study.best_trial
        if best_trial.user_attrs:
            f.write(f"- ì—°ìœ¨í™” ìˆ˜ìµë¥ : {best_trial.user_attrs.get('annual_return', 0):.2%}\n")
            f.write(f"- MDD: {best_trial.user_attrs.get('mdd', 0):.2%}\n")
            f.write(f"- Sharpe: {best_trial.user_attrs.get('sharpe', 0):.2f}\n")
            f.write(f"- ì´ ìˆ˜ìµë¥ : {best_trial.user_attrs.get('total_return', 0):.2%}\n")
            f.write(f"- ë³€ë™ì„±: {best_trial.user_attrs.get('volatility', 0):.2%}\n")
            f.write(f"- ìŠ¹ë¥ : {best_trial.user_attrs.get('win_rate', 0):.2%}\n")
        
        f.write(f"\n## ìµœì  íŒŒë¼ë¯¸í„°\n\n")
        f.write(f"```yaml\n")
        f.write(yaml.dump(best_params, allow_unicode=True))
        f.write(f"```\n")
    
    logger.info(f"ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")
    logger.info(f"Study DB: {storage_path}")
    
    # ì‹œê°í™” (ì„ íƒ)
    if args.plot:
        try:
            import optuna.visualization as vis
            import plotly
            
            # Optimization history
            fig = vis.plot_optimization_history(study)
            plotly.offline.plot(fig, filename=str(output_dir / 'optimization_history.html'), auto_open=False)
            
            # Parameter importances
            fig = vis.plot_param_importances(study)
            plotly.offline.plot(fig, filename=str(output_dir / 'param_importances.html'), auto_open=False)
            
            logger.info(f"ì‹œê°í™” ì €ì¥: {output_dir}")
        except Exception as e:
            logger.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
    
    logger.info("=" * 60)
    logger.info("ìµœì í™” ì™„ë£Œ")
    logger.info("=" * 60)
    
    return 0


def cmd_walk_forward(args):
    """ì›Œí¬í¬ì›Œë“œ ë¶„ì„ ëª…ë ¹"""
    from datetime import datetime
    from pathlib import Path
    from extensions.optuna.walk_forward import run_walk_forward
    
    logger.info("=" * 60)
    logger.info("ì›Œí¬í¬ì›Œë“œ ë¶„ì„ ì‹œì‘")
    logger.info("=" * 60)
    
    # ë‚ ì§œ íŒŒì‹±
    start_date = datetime.strptime(args.start, '%Y-%m-%d').date()
    end_date = datetime.strptime(args.end, '%Y-%m-%d').date()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    if args.output:
        output_dir = Path(args.output)
    else:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = Path(f'reports/walk_forward/{args.window_type}_{timestamp}')
    
    # ì‹¤í–‰
    results = run_walk_forward(
        start_date=start_date,
        end_date=end_date,
        train_months=args.train_months,
        test_months=args.test_months,
        window_type=args.window_type,
        n_trials=args.trials,
        output_dir=output_dir,
        seed=args.seed
    )
    
    logger.info("=" * 60)
    logger.info("ì›Œí¬í¬ì›Œë“œ ë¶„ì„ ì™„ë£Œ")
    logger.info("=" * 60)
    
    return 0


def cmd_robustness(args):
    """ë¡œë²„ìŠ¤íŠ¸ë‹ˆìŠ¤ í…ŒìŠ¤íŠ¸ ëª…ë ¹"""
    from datetime import datetime
    from pathlib import Path
    import json
    from extensions.optuna.robustness import run_robustness_tests
    
    logger.info("=" * 60)
    logger.info("ë¡œë²„ìŠ¤íŠ¸ë‹ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 60)
    
    # ë‚ ì§œ íŒŒì‹±
    start_date = datetime.strptime(args.start, '%Y-%m-%d').date()
    end_date = datetime.strptime(args.end, '%Y-%m-%d').date()
    
    # íŒŒë¼ë¯¸í„° ë¡œë“œ
    params_file = Path(args.params)
    if not params_file.exists():
        logger.error(f"íŒŒë¼ë¯¸í„° íŒŒì¼ ì—†ìŒ: {params_file}")
        return 1
    
    with open(params_file, 'r', encoding='utf-8') as f:
        base_params = json.load(f)
    
    logger.info(f"ê¸°ë³¸ íŒŒë¼ë¯¸í„°: {base_params}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    if args.output:
        output_dir = Path(args.output)
    else:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = Path(f'reports/robustness/{timestamp}')
    
    # ì‹¤í–‰
    results = run_robustness_tests(
        base_params=base_params,
        start_date=start_date,
        end_date=end_date,
        n_iterations=args.iterations,
        output_dir=output_dir,
        seed=args.seed
    )
    
    logger.info("=" * 60)
    logger.info("ë¡œë²„ìŠ¤íŠ¸ë‹ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info("=" * 60)
    
    return 0


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='KRX Alertor - PC CLI',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ë°ì´í„° ì—…ë°ì´íŠ¸
  python pc/cli.py update --date auto
  
  # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  python pc/cli.py backtest --start 2024-01-01 --output reports/backtest_2024
  
  # ë§¤ë§¤ ì‹ í˜¸ ìŠ¤ìº”
  python pc/cli.py scan --date auto --top-n 10
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹')
    
    # update ëª…ë ¹
    parser_update = subparsers.add_parser('update', help='ë°ì´í„° ì—…ë°ì´íŠ¸')
    parser_update.add_argument('--date', default='auto', help='ì¢…ë£Œì¼ (YYYY-MM-DD ë˜ëŠ” auto)')
    parser_update.add_argument('--symbols', help='íŠ¹ì • ì¢…ëª©ë§Œ (ì‰¼í‘œ êµ¬ë¶„)')
    parser_update.add_argument('--force', action='store_true', help='ê°•ì œ ì—…ë°ì´íŠ¸')
    parser_update.set_defaults(func=cmd_update_data)
    
    # backtest ëª…ë ¹
    parser_backtest = subparsers.add_parser('backtest', help='ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
    parser_backtest.add_argument('--start', required=True, help='ì‹œì‘ì¼ (YYYY-MM-DD)')
    parser_backtest.add_argument('--end', default='today', help='ì¢…ë£Œì¼ (YYYY-MM-DD ë˜ëŠ” today)')
    parser_backtest.add_argument('--capital', type=int, default=10000000, help='ì´ˆê¸° ìë³¸ (ê¸°ë³¸: 1ì²œë§Œì›)')
    parser_backtest.add_argument('--max-positions', type=int, default=10, help='ìµœëŒ€ ë³´ìœ  ì¢…ëª© ìˆ˜')
    parser_backtest.add_argument('--rebalance', default='monthly', choices=['daily', 'weekly', 'monthly'], help='ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°')
    parser_backtest.add_argument('--universe', help='ìœ ë‹ˆë²„ìŠ¤ (ì‰¼í‘œ êµ¬ë¶„, ë¯¸ì§€ì •ì‹œ ìë™ í•„í„°ë§)')
    parser_backtest.add_argument('--output', help='ë¦¬í¬íŠ¸ ì €ì¥ ê²½ë¡œ')
    parser_backtest.set_defaults(func=cmd_backtest)
    
    # scan ëª…ë ¹
    parser_scan = subparsers.add_parser('scan', help='ë§¤ë§¤ ì‹ í˜¸ ìŠ¤ìº”')
    parser_scan.add_argument('--date', default='auto', help='ìŠ¤ìº” ë‚ ì§œ (YYYY-MM-DD ë˜ëŠ” auto)')
    parser_scan.add_argument('--min-confidence', type=float, default=0.6, help='ìµœì†Œ ì‹ ë¢°ë„ (ê¸°ë³¸: 0.6)')
    parser_scan.add_argument('--top-n', type=int, default=10, help='ìƒìœ„ Nê°œ (ê¸°ë³¸: 10)')
    parser_scan.add_argument('--output', help='ì‹ í˜¸ ì €ì¥ ê²½ë¡œ (CSV)')
    parser_scan.add_argument('--notify', action='store_true', help='í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡')
    parser_scan.set_defaults(func=cmd_scan)
    
    # optimize ëª…ë ¹
    parser_optimize = subparsers.add_parser('optimize', help='íŒŒë¼ë¯¸í„° ìµœì í™” (Optuna)')
    parser_optimize.add_argument('--start', required=True, help='ì‹œì‘ì¼ (YYYY-MM-DD)')
    parser_optimize.add_argument('--end', default='today', help='ì¢…ë£Œì¼ (YYYY-MM-DD ë˜ëŠ” today)')
    parser_optimize.add_argument('--capital', type=int, default=10000000, help='ì´ˆê¸° ìë³¸ (ê¸°ë³¸: 1ì²œë§Œì›)')
    parser_optimize.add_argument('--trials', type=int, default=100, help='Trial ìˆ˜ (ê¸°ë³¸: 100)')
    parser_optimize.add_argument('--timeout', type=int, help='íƒ€ì„ì•„ì›ƒ (ì´ˆ)')
    parser_optimize.add_argument('--mdd-lambda', type=float, default=2.0, help='MDD íŒ¨ë„í‹° ê³„ìˆ˜ (ê¸°ë³¸: 2.0)')
    parser_optimize.add_argument('--seed', type=int, default=42, help='ëœë¤ ì‹œë“œ (ì¬í˜„ì„±)')
    parser_optimize.add_argument('--output', help='ê²°ê³¼ ì €ì¥ ê²½ë¡œ')
    parser_optimize.add_argument('--plot', action='store_true', help='ì‹œê°í™” ìƒì„±')
    parser_optimize.set_defaults(func=cmd_optimize)
    
    # walk-forward ëª…ë ¹
    parser_wf = subparsers.add_parser('walk-forward', help='ì›Œí¬í¬ì›Œë“œ ë¶„ì„')
    parser_wf.add_argument('--start', required=True, help='ì‹œì‘ì¼ (YYYY-MM-DD)')
    parser_wf.add_argument('--end', required=True, help='ì¢…ë£Œì¼ (YYYY-MM-DD)')
    parser_wf.add_argument('--train-months', type=int, default=12, help='í•™ìŠµ ê¸°ê°„ (ê°œì›”)')
    parser_wf.add_argument('--test-months', type=int, default=3, help='ê²€ì¦ ê¸°ê°„ (ê°œì›”)')
    parser_wf.add_argument('--window-type', choices=['sliding', 'expanding'], default='sliding', help='ìœˆë„ìš° íƒ€ì…')
    parser_wf.add_argument('--trials', type=int, default=50, help='ê° ìœˆë„ìš°ë‹¹ Optuna trials')
    parser_wf.add_argument('--seed', type=int, default=42, help='ëœë¤ ì‹œë“œ')
    parser_wf.add_argument('--output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser_wf.set_defaults(func=cmd_walk_forward)
    
    # robustness ëª…ë ¹
    parser_robust = subparsers.add_parser('robustness', help='ë¡œë²„ìŠ¤íŠ¸ë‹ˆìŠ¤ í…ŒìŠ¤íŠ¸')
    parser_robust.add_argument('--start', required=True, help='ì‹œì‘ì¼ (YYYY-MM-DD)')
    parser_robust.add_argument('--end', required=True, help='ì¢…ë£Œì¼ (YYYY-MM-DD)')
    parser_robust.add_argument('--params', required=True, help='íŒŒë¼ë¯¸í„° JSON íŒŒì¼ ê²½ë¡œ')
    parser_robust.add_argument('--iterations', type=int, default=30, help='ë°˜ë³µ íšŸìˆ˜')
    parser_robust.add_argument('--seed', type=int, default=42, help='ëœë¤ ì‹œë“œ')
    parser_robust.add_argument('--output', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser_robust.set_defaults(func=cmd_robustness)
    
    # íŒŒì‹±
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return 1
    
    # ëª…ë ¹ ì‹¤í–‰
    try:
        return args.func(args)
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return 1


if __name__ == '__main__':
    sys.exit(main())

# -*- coding: utf-8 -*-
"""
tests/tuning/test_gate2_loop.py
Gate2 WF outsample ì•ˆì •ì„± ê²€ì¦ ë£¨í”„

ì‹¤í–‰: python -m tests.tuning.test_gate2_loop --trials 30 --seed 42 --runs 3

ëª©ì :
- Gate1 â†’ Gate2ê¹Œì§€ ë°˜ë³µ ì‹¤í–‰ (Gate3ëŠ” í•˜ì§€ ì•ŠìŒ)
- WF outsampleì´ ì•ˆì •ì ìœ¼ë¡œ í†µê³¼ë˜ëŠ”ì§€ í™•ì¸
- TEST_MODE OFF ìƒíƒœë¡œ ì‹¤í–‰ (skip í”Œë˜ê·¸ ì‚¬ìš© ë¶ˆê°€)
- ë£©ë°±ë³„ cache_key êµ¬ë¶„ í™•ì¸

ì£¼ì˜:
- ì‹¤ì œ ë°ì´í„° ì—°ê²° ì‹œ use_mock=Falseë¡œ ë³€ê²½
"""
import logging
import sys
from datetime import date
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    import optuna

    optuna.logging.set_verbosity(optuna.logging.WARNING)
except ImportError:
    print("âŒ optuna íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install optuna")
    sys.exit(1)

from extensions.tuning import (
    BacktestMetrics,
    BacktestRunResult,
    Period,
    SplitConfig,
    CostConfig,
    DataConfig,
    DEFAULT_COSTS,
    TuningObjective,
    MiniWalkForward,
    check_gate1,
    check_gate2,
    deduplicate_top_n_candidates,
    run_backtest_for_tuning,
    clear_global_cache,
    create_manifest,
    save_manifest,
    compute_universe_hash,
)
from extensions.tuning.gates import is_test_mode

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)
logger = logging.getLogger(__name__)


def get_trading_calendar(start: date, end: date) -> list:
    """ê±°ë˜ì¼ ìº˜ë¦°ë” ìƒì„± (ì£¼ë§ ì œì™¸)"""
    from datetime import timedelta

    calendar = []
    current = start
    while current <= end:
        if current.weekday() < 5:
            calendar.append(current)
        current += timedelta(days=1)
    return calendar


def get_universe() -> list:
    """ETF ìœ ë‹ˆë²„ìŠ¤"""
    return [
        "069500",  # KODEX 200
        "102110",  # TIGER 200
        "229200",  # KODEX ì½”ìŠ¤ë‹¥150
        "114800",  # KODEX ì¸ë²„ìŠ¤
        "122630",  # KODEX ë ˆë²„ë¦¬ì§€
        "233740",  # KODEX ì½”ìŠ¤ë‹¥150ë ˆë²„ë¦¬ì§€
        "252670",  # KODEX 200ì„ ë¬¼ì¸ë²„ìŠ¤2X
        "261240",  # KODEX ë¯¸êµ­S&P500ì„ ë¬¼(H)
        "305720",  # KODEX 2ì°¨ì „ì§€ì‚°ì—…
        "091160",  # KODEX ë°˜ë„ì²´
    ]


def run_gate2_loop(
    n_trials: int = 30,
    seed: int = 42,
    top_n: int = 5,
    n_runs: int = 3,
    use_mock: bool = True,
):
    """
    Gate2 WF outsample ì•ˆì •ì„± ê²€ì¦ ë£¨í”„

    Args:
        n_trials: ì‹œí–‰ íšŸìˆ˜
        seed: ëœë¤ ì‹œë“œ
        top_n: Gate1 Top-N
        n_runs: ë°˜ë³µ ì‹¤í–‰ íšŸìˆ˜
        use_mock: Mock ì‚¬ìš© ì—¬ë¶€
    """
    print("\n" + "#" * 60)
    print("# Gate2 WF Outsample ì•ˆì •ì„± ê²€ì¦ ë£¨í”„")
    print(f"# n_trials={n_trials}, seed={seed}, top_n={top_n}, n_runs={n_runs}")
    print(f"# TEST_MODE={is_test_mode()}, use_mock={use_mock}")
    print("#" * 60)

    # TEST_MODE í™•ì¸ (OFFì—¬ì•¼ í•¨)
    if is_test_mode():
        print("\nâš ï¸ ê²½ê³ : TEST_MODEê°€ ONì…ë‹ˆë‹¤. ì‹¤ì „ ê²€ì¦ì„ ìœ„í•´ OFF ìƒíƒœë¡œ ì‹¤í–‰í•˜ì„¸ìš”.")

    # ìœ ë‹ˆë²„ìŠ¤
    universe = get_universe()
    universe_hash = compute_universe_hash(universe)

    print(f"\n[ìœ ë‹ˆë²„ìŠ¤]")
    print(f"  ì¢…ëª© ìˆ˜: {len(universe)}")
    print(f"  universe_hash: {universe_hash[:16]}...")

    # Mock íŒ¨ì¹˜
    if use_mock:
        print(f"\nâš ï¸ Mock ëª¨ë“œë¡œ ì‹¤í–‰")
        import extensions.tuning.runner as runner_module
        from tests.tuning.test_mini_tuning import (
            mock_run_single_backtest,
            MockBacktestService,
        )

        original_func = runner_module._run_single_backtest
        runner_module._run_single_backtest = mock_run_single_backtest

        import tests.tuning.test_mini_tuning as mini_tuning_module

    # ê²°ê³¼ ì €ì¥
    all_run_results = []

    try:
        for run_idx in range(n_runs):
            run_seed = seed + run_idx * 100
            print("\n" + "=" * 60)
            print(f"Run {run_idx + 1}/{n_runs} (seed={run_seed})")
            print("=" * 60)

            # Mock ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (runë§ˆë‹¤ ë‹¤ë¥¸ seed)
            if use_mock:
                mini_tuning_module._mock_service = MockBacktestService(run_seed)

            clear_global_cache()

            # ê¸°ê°„ ì„¤ì • (runë§ˆë‹¤ ì•½ê°„ ë‹¤ë¥´ê²Œ)
            end_date = date(2024, 6, 30)
            start_date = date(2020 - run_idx, 1, 1)  # 2020, 2019, 2018...

            trading_calendar = get_trading_calendar(start_date, end_date)

            print(f"\n  ê¸°ê°„: {start_date} ~ {end_date} ({len(trading_calendar)}ì¼)")

            # ì„¤ì •
            lookbacks = [3, 6, 12]
            param_ranges = {
                "ma_period": {"min": 20, "max": 100, "step": 10, "type": "int"},
                "rsi_period": {"min": 5, "max": 25, "step": 5, "type": "int"},
            }

            split_config = SplitConfig()
            data_config = DataConfig(
                data_version="mock_v1" if use_mock else "real_v1",
                universe_version="etf_small_v1",
                universe_hash=universe_hash,
                universe_count=len(universe),
            )

            # ============================================================
            # Phase 1: íŠœë‹ ì‹¤í–‰
            # ============================================================
            print(f"\n  [Phase 1] íŠœë‹ ì‹¤í–‰ (n_trials={n_trials})")

            objective = TuningObjective(
                start_date=start_date,
                end_date=end_date,
                trading_calendar=trading_calendar,
                lookbacks=lookbacks,
                param_ranges=param_ranges,
                split_config=split_config,
                data_config=data_config,
            )

            sampler = optuna.samplers.TPESampler(seed=run_seed)
            study = optuna.create_study(direction="maximize", sampler=sampler)
            study.optimize(objective, n_trials=n_trials, show_progress_bar=False)

            stats = objective.get_stats()
            print(f"    ì™„ë£Œ: {stats['trial_count']}ê±´, ê°€ë“œë ˆì¼ ì‹¤íŒ¨: {stats['guardrail_failures']}ê±´")

            # ============================================================
            # Phase 2: Gate 1 - Top-N ì„ ì •
            # ============================================================
            print(f"\n  [Phase 2] Gate 1 - Top-N ì„ ì •")

            completed_trials = [
                t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE
            ]

            candidates = []
            for trial in completed_trials:
                if "val_sharpe" in trial.user_attrs:
                    candidates.append(
                        {
                            "trial_number": trial.number,
                            "params": trial.params,
                            "val_sharpe": trial.user_attrs["val_sharpe"],
                            "params_hash": trial.user_attrs.get("params_hash", ""),
                        }
                    )

            deduped_candidates = deduplicate_top_n_candidates(candidates, top_n=top_n)
            print(f"    í›„ë³´: {len(candidates)} â†’ {len(deduped_candidates)} (ì¤‘ë³µ ì œê±°)")

            gate1_passed = []
            for c in deduped_candidates:
                result = run_backtest_for_tuning(
                    params=c["params"],
                    start_date=start_date,
                    end_date=end_date,
                    lookback_months=12,
                    trading_calendar=trading_calendar,
                    use_cache=True,
                )

                # Gate1: skip í”Œë˜ê·¸ ì—†ì´ ì‹¤í–‰ (TEST_MODE OFF)
                # Mock ë°ì´í„°ì—ì„œëŠ” logic_check/mdd_checkê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ
                # ì‹¤ì œ ë°ì´í„°ì—ì„œëŠ” í†µê³¼í•´ì•¼ í•¨
                try:
                    gate1_result = check_gate1(
                        result,
                        top_n=top_n,
                        skip_logic_check=False,
                        skip_mdd_check=False,
                    )
                except RuntimeError as e:
                    # TEST_MODE OFFì—ì„œ skip í”Œë˜ê·¸ ì‚¬ìš© ì‹œ ì—ëŸ¬
                    print(f"    âŒ RuntimeError: {e}")
                    continue

                if gate1_result.passed:
                    gate1_passed.append(
                        {**c, "result": result, "gate1_result": gate1_result}
                    )
                    print(f"    âœ… Trial #{c['trial_number']}: Val Sharpe={c['val_sharpe']:.3f}")
                else:
                    print(f"    âŒ Trial #{c['trial_number']}: {gate1_result.failures[:2]}")

            print(f"    Gate 1 í†µê³¼: {len(gate1_passed)}/{len(deduped_candidates)}")

            if not gate1_passed:
                print(f"    âš ï¸ Gate 1 í†µê³¼ í›„ë³´ ì—†ìŒ - ë‹¤ìŒ runìœ¼ë¡œ")
                all_run_results.append(
                    {
                        "run": run_idx + 1,
                        "seed": run_seed,
                        "gate1_passed": 0,
                        "gate2_passed": 0,
                        "best_stability": None,
                    }
                )
                continue

            # ============================================================
            # Phase 3: Gate 2 - WF Outsample ì•ˆì •ì„±
            # ============================================================
            print(f"\n  [Phase 3] Gate 2 - WF Outsample ì•ˆì •ì„±")

            gate2_passed = []
            for c in gate1_passed:
                # Mini Walk-Forward ì‹¤í–‰
                wf = MiniWalkForward(
                    start_date=start_date,
                    end_date=end_date,
                    trading_calendar=trading_calendar,
                    train_months=12,
                    val_months=3,
                    outsample_months=3,
                    stride_months=6,
                )

                wf_results_list = wf.run(c["params"])

                # WF ê²°ê³¼ë¥¼ Gate2 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                wf_results = [
                    {"sharpe": r.outsample_metrics.sharpe if r.outsample_metrics else 0}
                    for r in wf_results_list
                ]

                gate2_result = check_gate2(
                    c["result"],
                    wf_results,
                    min_stability_score=1.0,
                    min_win_rate=0.60,
                )

                stability = gate2_result.metadata.get("stability_score", 0)
                win_rate = gate2_result.metadata.get("win_rate", 0)

                if gate2_result.passed:
                    gate2_passed.append(
                        {
                            **c,
                            "gate2_result": gate2_result,
                            "wf_results": wf_results_list,
                            "stability_score": stability,
                            "win_rate": win_rate,
                        }
                    )
                    print(
                        f"    âœ… Trial #{c['trial_number']}: "
                        f"stability={stability:.2f}, win_rate={win_rate:.0%}"
                    )
                else:
                    print(
                        f"    âŒ Trial #{c['trial_number']}: "
                        f"stability={stability:.2f}, win_rate={win_rate:.0%} - {gate2_result.failures}"
                    )

            print(f"    Gate 2 í†µê³¼: {len(gate2_passed)}/{len(gate1_passed)}")

            # ê²°ê³¼ ì €ì¥
            best_stability = max([c["stability_score"] for c in gate2_passed], default=None)
            all_run_results.append(
                {
                    "run": run_idx + 1,
                    "seed": run_seed,
                    "period": f"{start_date}~{end_date}",
                    "gate1_passed": len(gate1_passed),
                    "gate2_passed": len(gate2_passed),
                    "best_stability": best_stability,
                }
            )

            # Manifest ì €ì¥ (stage=gate2)
            if gate2_passed:
                best_candidate = max(gate2_passed, key=lambda x: x["stability_score"])
                manifest = create_manifest(
                    stage="gate2",
                    start_date=start_date,
                    end_date=end_date,
                    lookbacks=lookbacks,
                    trials=n_trials,
                    split_config=split_config,
                    costs=DEFAULT_COSTS,
                    data_config=data_config,
                    param_ranges=param_ranges,
                    best_result=best_candidate["result"],
                    all_trials_count=len(study.trials),
                    random_seed=run_seed,
                )

                output_dir = Path(__file__).parent.parent.parent / "data" / "tuning_test"
                filepath = save_manifest(manifest, output_dir)
                print(f"    Manifest: {filepath.name}")

        # ============================================================
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        # ============================================================
        print("\n" + "=" * 60)
        print("Gate2 ë£¨í”„ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)

        print(f"\n  {'Run':<5} {'Seed':<8} {'Period':<25} {'G1':<5} {'G2':<5} {'Best Stab':<10}")
        print("  " + "-" * 60)
        for r in all_run_results:
            period = r.get("period", "N/A")
            stab = f"{r['best_stability']:.2f}" if r["best_stability"] else "N/A"
            print(
                f"  {r['run']:<5} {r['seed']:<8} {period:<25} "
                f"{r['gate1_passed']:<5} {r['gate2_passed']:<5} {stab:<10}"
            )

        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        gate2_success_count = sum(1 for r in all_run_results if r["gate2_passed"] > 0)
        success_rate = gate2_success_count / n_runs if n_runs > 0 else 0

        print(f"\n  Gate2 í†µê³¼ run: {gate2_success_count}/{n_runs} ({success_rate:.0%})")

        if success_rate >= 0.5:
            print(f"\n  ğŸ‰ Gate2 WF outsample ì•ˆì •ì„± ê²€ì¦ ì„±ê³µ!")
            return True
        else:
            print(f"\n  âš ï¸ Gate2 í†µê³¼ìœ¨ ë‚®ìŒ - íŒŒë¼ë¯¸í„°/ìœ ë‹ˆë²„ìŠ¤ ì¡°ì • í•„ìš”")
            return False

    finally:
        if use_mock:
            runner_module._run_single_backtest = original_func


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Gate2 WF Outsample ì•ˆì •ì„± ê²€ì¦ ë£¨í”„")
    parser.add_argument("--trials", type=int, default=30, help="ì‹œí–‰ íšŸìˆ˜ (ê¸°ë³¸: 30)")
    parser.add_argument("--seed", type=int, default=42, help="ëœë¤ ì‹œë“œ (ê¸°ë³¸: 42)")
    parser.add_argument("--top-n", type=int, default=5, help="Top-N (ê¸°ë³¸: 5)")
    parser.add_argument("--runs", type=int, default=3, help="ë°˜ë³µ ì‹¤í–‰ íšŸìˆ˜ (ê¸°ë³¸: 3)")
    parser.add_argument("--real", action="store_true", help="ì‹¤ì œ ë°ì´í„° ì‚¬ìš© (ê¸°ë³¸: Mock)")

    args = parser.parse_args()

    success = run_gate2_loop(
        n_trials=args.trials,
        seed=args.seed,
        top_n=args.top_n,
        n_runs=args.runs,
        use_mock=not args.real,
    )
    sys.exit(0 if success else 1)
